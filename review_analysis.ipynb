{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "# Libraries for sentiment analysis\n",
    "import nltk\n",
    "nltk.download()\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False # Solve error in autocomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Extract dataframes from zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(os.getcwd(), 'data')\n",
    "FILE_PATH_SEATTLE = os.path.join(DATA_PATH, 'seattle.zip')\n",
    "FILE_PATH_BOSTON = os.path.join(DATA_PATH, 'boston.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_df_from_airbnb_zipfile(PATH_ZIPFILE) :\n",
    "    ''' \n",
    "    Extract csv files from a zipfile and return a list of dataframes\n",
    "    \n",
    "    INPUT  : file path to a zipfile to open\n",
    "    OUTPUT : a dictionary that contains dataframes of files \n",
    "    extracted from the zip file\n",
    "    '''\n",
    "\n",
    "    zf = ZipFile(PATH_ZIPFILE) \n",
    "    dfs = {\n",
    "        text_file.filename : pd.read_csv(zf.open(text_file.filename ))\n",
    "        for text_file in zf.infolist() \n",
    "        if text_file.filename.endswith('.csv')\n",
    "    }\n",
    "    \n",
    "    print('Printing a dictionary with filenames as keys')\n",
    "    for filename in dfs.keys() :\n",
    "        print(f'Filename (keys): {filename}')\n",
    "    \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Seattle data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a dictionary with filenames as keys\n",
      "Filename (keys): calendar.csv\n",
      "Filename (keys): listings.csv\n",
      "Filename (keys): reviews.csv\n"
     ]
    }
   ],
   "source": [
    "dfs_seattle = extract_df_from_airbnb_zipfile(FILE_PATH_SEATTLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7202016</td>\n",
       "      <td>38917982</td>\n",
       "      <td>2015-07-19</td>\n",
       "      <td>28943674</td>\n",
       "      <td>Bianca</td>\n",
       "      <td>Cute and cozy place. Perfect location to every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7202016</td>\n",
       "      <td>39087409</td>\n",
       "      <td>2015-07-20</td>\n",
       "      <td>32440555</td>\n",
       "      <td>Frank</td>\n",
       "      <td>Kelly has a great room in a very central locat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7202016</td>\n",
       "      <td>39820030</td>\n",
       "      <td>2015-07-26</td>\n",
       "      <td>37722850</td>\n",
       "      <td>Ian</td>\n",
       "      <td>Very spacious apartment, and in a great neighb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7202016</td>\n",
       "      <td>40813543</td>\n",
       "      <td>2015-08-02</td>\n",
       "      <td>33671805</td>\n",
       "      <td>George</td>\n",
       "      <td>Close to Seattle Center and all it has to offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7202016</td>\n",
       "      <td>41986501</td>\n",
       "      <td>2015-08-10</td>\n",
       "      <td>34959538</td>\n",
       "      <td>Ming</td>\n",
       "      <td>Kelly was a great host and very accommodating ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id        id        date  reviewer_id reviewer_name  \\\n",
       "0     7202016  38917982  2015-07-19     28943674        Bianca   \n",
       "1     7202016  39087409  2015-07-20     32440555         Frank   \n",
       "2     7202016  39820030  2015-07-26     37722850           Ian   \n",
       "3     7202016  40813543  2015-08-02     33671805        George   \n",
       "4     7202016  41986501  2015-08-10     34959538          Ming   \n",
       "\n",
       "                                            comments  \n",
       "0  Cute and cozy place. Perfect location to every...  \n",
       "1  Kelly has a great room in a very central locat...  \n",
       "2  Very spacious apartment, and in a great neighb...  \n",
       "3  Close to Seattle Center and all it has to offe...  \n",
       "4  Kelly was a great host and very accommodating ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_seattle = dfs_seattle['reviews.csv']\n",
    "reviews_seattle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84849 entries, 0 to 84848\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   listing_id     84849 non-null  int64 \n",
      " 1   id             84849 non-null  int64 \n",
      " 2   date           84849 non-null  object\n",
      " 3   reviewer_id    84849 non-null  int64 \n",
      " 4   reviewer_name  84849 non-null  object\n",
      " 5   comments       84831 non-null  object\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "reviews_seattle.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 18 missing comments and date is not in datetime object.\n",
    "As `comments` is the key feature for the sentivity analysis, any records missing comments will be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping null values in 'comments' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataframe for cleaning\n",
    "df_copy = reviews_seattle.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11034</th>\n",
       "      <td>461567</td>\n",
       "      <td>11614247</td>\n",
       "      <td>2014-04-09</td>\n",
       "      <td>12120141</td>\n",
       "      <td>Abbey</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15383</th>\n",
       "      <td>9460</td>\n",
       "      <td>10563024</td>\n",
       "      <td>2014-02-24</td>\n",
       "      <td>12498029</td>\n",
       "      <td>Debra</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15914</th>\n",
       "      <td>2906694</td>\n",
       "      <td>48629316</td>\n",
       "      <td>2015-09-27</td>\n",
       "      <td>44218980</td>\n",
       "      <td>Anush</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16097</th>\n",
       "      <td>910784</td>\n",
       "      <td>9950520</td>\n",
       "      <td>2014-01-21</td>\n",
       "      <td>179481</td>\n",
       "      <td>Enrico</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27280</th>\n",
       "      <td>10695</td>\n",
       "      <td>52378</td>\n",
       "      <td>2010-06-13</td>\n",
       "      <td>105412</td>\n",
       "      <td>Wei</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29467</th>\n",
       "      <td>1018204</td>\n",
       "      <td>10024984</td>\n",
       "      <td>2014-01-26</td>\n",
       "      <td>10571694</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30619</th>\n",
       "      <td>6079216</td>\n",
       "      <td>34824019</td>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>31556342</td>\n",
       "      <td>Mack</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31414</th>\n",
       "      <td>3354614</td>\n",
       "      <td>18103248</td>\n",
       "      <td>2014-08-21</td>\n",
       "      <td>12426758</td>\n",
       "      <td>Jeff</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35210</th>\n",
       "      <td>3554558</td>\n",
       "      <td>24863045</td>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>24488791</td>\n",
       "      <td>Eleanor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37971</th>\n",
       "      <td>1790020</td>\n",
       "      <td>15640556</td>\n",
       "      <td>2014-07-13</td>\n",
       "      <td>16884291</td>\n",
       "      <td>Michael</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40176</th>\n",
       "      <td>23430</td>\n",
       "      <td>8347394</td>\n",
       "      <td>2013-10-27</td>\n",
       "      <td>5034901</td>\n",
       "      <td>Jim</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41251</th>\n",
       "      <td>774659</td>\n",
       "      <td>7116754</td>\n",
       "      <td>2013-09-07</td>\n",
       "      <td>7654662</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47183</th>\n",
       "      <td>585418</td>\n",
       "      <td>10782872</td>\n",
       "      <td>2014-03-07</td>\n",
       "      <td>11979005</td>\n",
       "      <td>Felecia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61026</th>\n",
       "      <td>231097</td>\n",
       "      <td>31247122</td>\n",
       "      <td>2015-05-03</td>\n",
       "      <td>2152222</td>\n",
       "      <td>Sehar</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61176</th>\n",
       "      <td>5682</td>\n",
       "      <td>64918</td>\n",
       "      <td>2010-07-15</td>\n",
       "      <td>145644</td>\n",
       "      <td>Keri</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64412</th>\n",
       "      <td>6759104</td>\n",
       "      <td>57492182</td>\n",
       "      <td>2015-12-26</td>\n",
       "      <td>40294811</td>\n",
       "      <td>Zareth</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71922</th>\n",
       "      <td>8294379</td>\n",
       "      <td>56583503</td>\n",
       "      <td>2015-12-14</td>\n",
       "      <td>29068286</td>\n",
       "      <td>Michael</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76589</th>\n",
       "      <td>84030</td>\n",
       "      <td>11782337</td>\n",
       "      <td>2014-04-14</td>\n",
       "      <td>5270791</td>\n",
       "      <td>Robert</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       listing_id        id        date  reviewer_id reviewer_name comments\n",
       "11034      461567  11614247  2014-04-09     12120141         Abbey      NaN\n",
       "15383        9460  10563024  2014-02-24     12498029         Debra      NaN\n",
       "15914     2906694  48629316  2015-09-27     44218980         Anush      NaN\n",
       "16097      910784   9950520  2014-01-21       179481        Enrico      NaN\n",
       "27280       10695     52378  2010-06-13       105412           Wei      NaN\n",
       "29467     1018204  10024984  2014-01-26     10571694        Jordan      NaN\n",
       "30619     6079216  34824019  2015-06-12     31556342          Mack      NaN\n",
       "31414     3354614  18103248  2014-08-21     12426758          Jeff      NaN\n",
       "35210     3554558  24863045  2015-01-03     24488791       Eleanor      NaN\n",
       "37971     1790020  15640556  2014-07-13     16884291       Michael      NaN\n",
       "40176       23430   8347394  2013-10-27      5034901           Jim      NaN\n",
       "41251      774659   7116754  2013-09-07      7654662     Elizabeth      NaN\n",
       "47183      585418  10782872  2014-03-07     11979005       Felecia      NaN\n",
       "61026      231097  31247122  2015-05-03      2152222         Sehar      NaN\n",
       "61176        5682     64918  2010-07-15       145644          Keri      NaN\n",
       "64412     6759104  57492182  2015-12-26     40294811        Zareth      NaN\n",
       "71922     8294379  56583503  2015-12-14     29068286       Michael      NaN\n",
       "76589       84030  11782337  2014-04-14      5270791        Robert      NaN"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting missing comments\n",
    "df_copy[df_copy['comments'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84831, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping records with missing comments \n",
    "df_copy = df_copy[df_copy['comments'].notnull()]\n",
    "df_copy.shape # 18 records deleted from 84849"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove blank records\n",
    "Some types there are blank reviews which are not recognized as NaN values. The below code is to find the index of blank entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "blanks = []\n",
    "\n",
    "for i, comment in enumerate(df_copy['comments']) :\n",
    "    if type(comment) == str : \n",
    "        if comment.isspace() : \n",
    "            blanks.append(i)\n",
    "            \n",
    "print(len(blanks))\n",
    "print(blanks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No blank records found!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting 'date' column into datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['date'] = pd.to_datetime(df_copy['date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breaking the date into year, month & day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['year'] = df_copy['date'].dt.year\n",
    "df_copy['month'] = df_copy['date'].dt.month\n",
    "df_copy['day'] = df_copy['date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_seattle_clean = df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised VADER Sentiment analysis\n",
    "For this project, nltk vader will be used to conduct polarity analysis (positive / negative) for the reviews. \n",
    "\n",
    "No label is provided to evaludate the test results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules\n",
    "Prerequisite : nltk.download('vader_lexcion') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate SentimentIntensityAnalyzer\n",
    "sent_analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kelly has a great room in a very central location. \r\n",
      "Beautiful building , architecture and a style that we really like. \r\n",
      "We felt guite at home here and wish we had spent more time.\r\n",
      "Went for a walk and found Seattle Center with a major food festival in progress. What a treat.\r\n",
      "Visited the Space Needle and the Chihuly Glass exhibit. Then Pikes Place Market. WOW.  Thanks for a great stay. \n",
      "\n",
      " {'neg': 0.0, 'neu': 0.609, 'pos': 0.391, 'compound': 0.9872}\n"
     ]
    }
   ],
   "source": [
    "sent1 = reviews_seattle_clean['comments'][1]\n",
    "print(sent1, '\\n\\n', sent_analyzer.polarity_scores(sent1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the official NLTK documentation, compound score is normalized the score to be between -1 and 1 using an alpha that approximates the max expected value. The official Github documentation can be found at the link [here](https://github.com/nltk/nltk/blob/develop/nltk/sentiment/vader.py)\n",
    "\n",
    "The review is generally positive given the sentences like 'What a treat', 'Wow' 'Thanks for a great stay' and the analyzer scores them fairly well -- compound score of 0.9872."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
