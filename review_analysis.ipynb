{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False # Solve error in autocomplete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Extract dataframes from zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(os.getcwd(), 'data')\n",
    "FILE_PATH_SEATTLE = os.path.join(DATA_PATH, 'seattle.zip')\n",
    "FILE_PATH_BOSTON = os.path.join(DATA_PATH, 'boston.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_df_from_airbnb_zipfile(PATH_ZIPFILE) :\n",
    "    ''' \n",
    "    Extract csv files from a zipfile and return a list of dataframes\n",
    "    \n",
    "    INPUT  : file path to a zipfile to open\n",
    "    OUTPUT : a dictionary that contains dataframes of files \n",
    "    extracted from the zip file\n",
    "    '''\n",
    "\n",
    "    zf = ZipFile(PATH_ZIPFILE) \n",
    "    dfs = {\n",
    "        text_file.filename : pd.read_csv(zf.open(text_file.filename ))\n",
    "        for text_file in zf.infolist() \n",
    "        if text_file.filename.endswith('.csv')\n",
    "    }\n",
    "    \n",
    "    print('Printing a dictionary with filenames as keys')\n",
    "    for filename in dfs.keys() :\n",
    "        print(f'Filename (keys): {filename}')\n",
    "    \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Seattle data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a dictionary with filenames as keys\n",
      "Filename (keys): calendar.csv\n",
      "Filename (keys): listings.csv\n",
      "Filename (keys): reviews.csv\n"
     ]
    }
   ],
   "source": [
    "dfs_seattle = extract_df_from_airbnb_zipfile(FILE_PATH_SEATTLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7202016</td>\n",
       "      <td>38917982</td>\n",
       "      <td>2015-07-19</td>\n",
       "      <td>28943674</td>\n",
       "      <td>Bianca</td>\n",
       "      <td>Cute and cozy place. Perfect location to every...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7202016</td>\n",
       "      <td>39087409</td>\n",
       "      <td>2015-07-20</td>\n",
       "      <td>32440555</td>\n",
       "      <td>Frank</td>\n",
       "      <td>Kelly has a great room in a very central locat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7202016</td>\n",
       "      <td>39820030</td>\n",
       "      <td>2015-07-26</td>\n",
       "      <td>37722850</td>\n",
       "      <td>Ian</td>\n",
       "      <td>Very spacious apartment, and in a great neighb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7202016</td>\n",
       "      <td>40813543</td>\n",
       "      <td>2015-08-02</td>\n",
       "      <td>33671805</td>\n",
       "      <td>George</td>\n",
       "      <td>Close to Seattle Center and all it has to offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7202016</td>\n",
       "      <td>41986501</td>\n",
       "      <td>2015-08-10</td>\n",
       "      <td>34959538</td>\n",
       "      <td>Ming</td>\n",
       "      <td>Kelly was a great host and very accommodating ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id        id        date  reviewer_id reviewer_name  \\\n",
       "0     7202016  38917982  2015-07-19     28943674        Bianca   \n",
       "1     7202016  39087409  2015-07-20     32440555         Frank   \n",
       "2     7202016  39820030  2015-07-26     37722850           Ian   \n",
       "3     7202016  40813543  2015-08-02     33671805        George   \n",
       "4     7202016  41986501  2015-08-10     34959538          Ming   \n",
       "\n",
       "                                            comments  \n",
       "0  Cute and cozy place. Perfect location to every...  \n",
       "1  Kelly has a great room in a very central locat...  \n",
       "2  Very spacious apartment, and in a great neighb...  \n",
       "3  Close to Seattle Center and all it has to offe...  \n",
       "4  Kelly was a great host and very accommodating ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_seattle = dfs_seattle['reviews.csv']\n",
    "reviews_seattle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84849 entries, 0 to 84848\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   listing_id     84849 non-null  int64 \n",
      " 1   id             84849 non-null  int64 \n",
      " 2   date           84849 non-null  object\n",
      " 3   reviewer_id    84849 non-null  int64 \n",
      " 4   reviewer_name  84849 non-null  object\n",
      " 5   comments       84831 non-null  object\n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 3.9+ MB\n"
     ]
    }
   ],
   "source": [
    "reviews_seattle.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 18 missing comments and date is not in datetime object.\n",
    "As `comments` is the key feature for the sentivity analysis, any records missing comments will be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping null values in 'comments' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the dataframe for cleaning\n",
    "df_copy = reviews_seattle.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11034</th>\n",
       "      <td>461567</td>\n",
       "      <td>11614247</td>\n",
       "      <td>2014-04-09</td>\n",
       "      <td>12120141</td>\n",
       "      <td>Abbey</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15383</th>\n",
       "      <td>9460</td>\n",
       "      <td>10563024</td>\n",
       "      <td>2014-02-24</td>\n",
       "      <td>12498029</td>\n",
       "      <td>Debra</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15914</th>\n",
       "      <td>2906694</td>\n",
       "      <td>48629316</td>\n",
       "      <td>2015-09-27</td>\n",
       "      <td>44218980</td>\n",
       "      <td>Anush</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16097</th>\n",
       "      <td>910784</td>\n",
       "      <td>9950520</td>\n",
       "      <td>2014-01-21</td>\n",
       "      <td>179481</td>\n",
       "      <td>Enrico</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27280</th>\n",
       "      <td>10695</td>\n",
       "      <td>52378</td>\n",
       "      <td>2010-06-13</td>\n",
       "      <td>105412</td>\n",
       "      <td>Wei</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29467</th>\n",
       "      <td>1018204</td>\n",
       "      <td>10024984</td>\n",
       "      <td>2014-01-26</td>\n",
       "      <td>10571694</td>\n",
       "      <td>Jordan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30619</th>\n",
       "      <td>6079216</td>\n",
       "      <td>34824019</td>\n",
       "      <td>2015-06-12</td>\n",
       "      <td>31556342</td>\n",
       "      <td>Mack</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31414</th>\n",
       "      <td>3354614</td>\n",
       "      <td>18103248</td>\n",
       "      <td>2014-08-21</td>\n",
       "      <td>12426758</td>\n",
       "      <td>Jeff</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35210</th>\n",
       "      <td>3554558</td>\n",
       "      <td>24863045</td>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>24488791</td>\n",
       "      <td>Eleanor</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37971</th>\n",
       "      <td>1790020</td>\n",
       "      <td>15640556</td>\n",
       "      <td>2014-07-13</td>\n",
       "      <td>16884291</td>\n",
       "      <td>Michael</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40176</th>\n",
       "      <td>23430</td>\n",
       "      <td>8347394</td>\n",
       "      <td>2013-10-27</td>\n",
       "      <td>5034901</td>\n",
       "      <td>Jim</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41251</th>\n",
       "      <td>774659</td>\n",
       "      <td>7116754</td>\n",
       "      <td>2013-09-07</td>\n",
       "      <td>7654662</td>\n",
       "      <td>Elizabeth</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47183</th>\n",
       "      <td>585418</td>\n",
       "      <td>10782872</td>\n",
       "      <td>2014-03-07</td>\n",
       "      <td>11979005</td>\n",
       "      <td>Felecia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61026</th>\n",
       "      <td>231097</td>\n",
       "      <td>31247122</td>\n",
       "      <td>2015-05-03</td>\n",
       "      <td>2152222</td>\n",
       "      <td>Sehar</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61176</th>\n",
       "      <td>5682</td>\n",
       "      <td>64918</td>\n",
       "      <td>2010-07-15</td>\n",
       "      <td>145644</td>\n",
       "      <td>Keri</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64412</th>\n",
       "      <td>6759104</td>\n",
       "      <td>57492182</td>\n",
       "      <td>2015-12-26</td>\n",
       "      <td>40294811</td>\n",
       "      <td>Zareth</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71922</th>\n",
       "      <td>8294379</td>\n",
       "      <td>56583503</td>\n",
       "      <td>2015-12-14</td>\n",
       "      <td>29068286</td>\n",
       "      <td>Michael</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76589</th>\n",
       "      <td>84030</td>\n",
       "      <td>11782337</td>\n",
       "      <td>2014-04-14</td>\n",
       "      <td>5270791</td>\n",
       "      <td>Robert</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       listing_id        id        date  reviewer_id reviewer_name comments\n",
       "11034      461567  11614247  2014-04-09     12120141         Abbey      NaN\n",
       "15383        9460  10563024  2014-02-24     12498029         Debra      NaN\n",
       "15914     2906694  48629316  2015-09-27     44218980         Anush      NaN\n",
       "16097      910784   9950520  2014-01-21       179481        Enrico      NaN\n",
       "27280       10695     52378  2010-06-13       105412           Wei      NaN\n",
       "29467     1018204  10024984  2014-01-26     10571694        Jordan      NaN\n",
       "30619     6079216  34824019  2015-06-12     31556342          Mack      NaN\n",
       "31414     3354614  18103248  2014-08-21     12426758          Jeff      NaN\n",
       "35210     3554558  24863045  2015-01-03     24488791       Eleanor      NaN\n",
       "37971     1790020  15640556  2014-07-13     16884291       Michael      NaN\n",
       "40176       23430   8347394  2013-10-27      5034901           Jim      NaN\n",
       "41251      774659   7116754  2013-09-07      7654662     Elizabeth      NaN\n",
       "47183      585418  10782872  2014-03-07     11979005       Felecia      NaN\n",
       "61026      231097  31247122  2015-05-03      2152222         Sehar      NaN\n",
       "61176        5682     64918  2010-07-15       145644          Keri      NaN\n",
       "64412     6759104  57492182  2015-12-26     40294811        Zareth      NaN\n",
       "71922     8294379  56583503  2015-12-14     29068286       Michael      NaN\n",
       "76589       84030  11782337  2014-04-14      5270791        Robert      NaN"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting missing comments\n",
    "df_copy[df_copy['comments'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84831, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping records with missing comments \n",
    "df_copy = df_copy[df_copy['comments'].notnull()]\n",
    "df_copy.shape # 18 records deleted from 84849"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove blank records\n",
    "Some types there are blank reviews which are not recognized as NaN values. The below code is to find the index of blank entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "blanks = []\n",
    "\n",
    "for i, comment in enumerate(df_copy['comments']) :\n",
    "    if type(comment) == str : \n",
    "        if comment.isspace() : \n",
    "            blanks.append(i)\n",
    "            \n",
    "print(len(blanks))\n",
    "print(blanks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No blank records found!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting 'date' column into datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['date'] = pd.to_datetime(df_copy['date'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breaking the date into year, month & day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy['year'] = df_copy['date'].dt.year\n",
    "df_copy['month'] = df_copy['date'].dt.month\n",
    "df_copy['day'] = df_copy['date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_seattle_clean = df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7202016</td>\n",
       "      <td>38917982</td>\n",
       "      <td>2015-07-19</td>\n",
       "      <td>28943674</td>\n",
       "      <td>Bianca</td>\n",
       "      <td>Cute and cozy place. Perfect location to every...</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7202016</td>\n",
       "      <td>39087409</td>\n",
       "      <td>2015-07-20</td>\n",
       "      <td>32440555</td>\n",
       "      <td>Frank</td>\n",
       "      <td>Kelly has a great room in a very central locat...</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7202016</td>\n",
       "      <td>39820030</td>\n",
       "      <td>2015-07-26</td>\n",
       "      <td>37722850</td>\n",
       "      <td>Ian</td>\n",
       "      <td>Very spacious apartment, and in a great neighb...</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id        id       date  reviewer_id reviewer_name  \\\n",
       "0     7202016  38917982 2015-07-19     28943674        Bianca   \n",
       "1     7202016  39087409 2015-07-20     32440555         Frank   \n",
       "2     7202016  39820030 2015-07-26     37722850           Ian   \n",
       "\n",
       "                                            comments  year  month  day  \n",
       "0  Cute and cozy place. Perfect location to every...  2015      7   19  \n",
       "1  Kelly has a great room in a very central locat...  2015      7   20  \n",
       "2  Very spacious apartment, and in a great neighb...  2015      7   26  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_seattle_clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the clean data\n",
    "reviews_seattle_clean.to_csv('data/review_seattle_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Modeling\n",
    "We can conduct sentiment analysis on comments to evaluate how positive or negative each comment is but the model cannot be quantitatively evaluated with test scores with no labels provided in this case.\n",
    "\n",
    "Instead, **topic modeling** will be performed to category the reviews into 10 common topics. \n",
    "\n",
    "Two algorithms will be trialed :\n",
    "1. Latent Dirichlet allocation, LDA\n",
    "2. Non-negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for topic modeling\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation, NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>comments</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7202016</td>\n",
       "      <td>38917982</td>\n",
       "      <td>2015-07-19</td>\n",
       "      <td>28943674</td>\n",
       "      <td>Bianca</td>\n",
       "      <td>Cute and cozy place. Perfect location to every...</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7202016</td>\n",
       "      <td>39087409</td>\n",
       "      <td>2015-07-20</td>\n",
       "      <td>32440555</td>\n",
       "      <td>Frank</td>\n",
       "      <td>Kelly has a great room in a very central locat...</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7202016</td>\n",
       "      <td>39820030</td>\n",
       "      <td>2015-07-26</td>\n",
       "      <td>37722850</td>\n",
       "      <td>Ian</td>\n",
       "      <td>Very spacious apartment, and in a great neighb...</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7202016</td>\n",
       "      <td>40813543</td>\n",
       "      <td>2015-08-02</td>\n",
       "      <td>33671805</td>\n",
       "      <td>George</td>\n",
       "      <td>Close to Seattle Center and all it has to offe...</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7202016</td>\n",
       "      <td>41986501</td>\n",
       "      <td>2015-08-10</td>\n",
       "      <td>34959538</td>\n",
       "      <td>Ming</td>\n",
       "      <td>Kelly was a great host and very accommodating ...</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id        id        date  reviewer_id reviewer_name  \\\n",
       "0     7202016  38917982  2015-07-19     28943674        Bianca   \n",
       "1     7202016  39087409  2015-07-20     32440555         Frank   \n",
       "2     7202016  39820030  2015-07-26     37722850           Ian   \n",
       "3     7202016  40813543  2015-08-02     33671805        George   \n",
       "4     7202016  41986501  2015-08-10     34959538          Ming   \n",
       "\n",
       "                                            comments  year  month  day  \n",
       "0  Cute and cozy place. Perfect location to every...  2015      7   19  \n",
       "1  Kelly has a great room in a very central locat...  2015      7   20  \n",
       "2  Very spacious apartment, and in a great neighb...  2015      7   26  \n",
       "3  Close to Seattle Center and all it has to offe...  2015      8    2  \n",
       "4  Kelly was a great host and very accommodating ...  2015      8   10  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/review_seattle_cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84831, 9)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL1 | Topic Modeling with LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanticate count vectorizer\n",
    "# remove English stopwords, \n",
    "# Ignore document frequency higher than max_df, lower than min_df\n",
    "cv = CountVectorizer(stop_words='english', max_df=0.90, min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the comments by number of word counts\n",
    "dtm = cv.fit_transform(df['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<84831x20096 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2450653 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate LDA model for 10 topics\n",
    "LDA_model = LatentDirichletAllocation(n_components=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the vectorized text to LDA model\n",
    "# LDA_model.fit(dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interrupted the above operations as fitting a LDA_model took too much time. Let's see if NMF model can be fit faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL2 | Topic Modeling with NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanticate tfidf vectorizer\n",
    "# remove English stopwords, \n",
    "# Ignore document frequency higher than max_df, lower than min_df\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_df=0.90, min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = tfidf.fit_transform(df['comments'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<84831x20096 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2450653 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm # 84831 vectorized words x 20096 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(max_iter=1000, n_components=10)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate NMF model and fit tfidf word vectors\n",
    "# max_iter set to 1000 to avoid convergence warning\n",
    "NMF_model = NMF(n_components=10, max_iter=1000) \n",
    "NMF_model.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20096)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NMF_model.components_.shape # 10 topics x 20096 coefficients to word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the most relevant words for Topic# 0\n",
      "['recommend', 'hosts', 'welcoming', 'thank', 'amazing', 'perfect', 'airbnb', 'host', 'welcome', 'staying', 'like', 'lovely', 'seattle', 'experience', 'felt', 'time', 'beautiful', 'feel', 'wonderful', 'home']\n",
      "\n",
      "Printing the most relevant words for Topic# 1\n",
      "['17', '11', '21', '13', '22', '10', '14', '12', '16', '18', '23', '38', 'day', 'host', 'days', 'arrival', 'reservation', 'posting', 'automated', 'canceled']\n",
      "\n",
      "Printing the most relevant words for Topic# 2\n",
      "['recommended', 'recommendations', 'price', 'check', 'overall', 'excellent', 'spot', 'accommodating', 'view', 'awesome', 'space', 'hosts', 'communication', 'easy', 'time', 'thanks', 'experience', 'host', 'location', 'great']\n",
      "\n",
      "Printing the most relevant words for Topic# 3\n",
      "['accommodating', 'fantastic', 'amazing', 'responsive', 'seattle', 'lauren', 'view', 'highly', 'needed', 'spacious', 'located', 'comfortable', 'building', 'check', 'helpful', 'recommend', 'perfect', 'location', 'clean', 'apartment']\n",
      "\n",
      "Printing the most relevant words for Topic# 4\n",
      "['neighbourhood', 'experience', 'area', 'little', 'touch', 'pretty', 'close', 'view', 'people', 'like', 'helpful', 'lot', 'quiet', 'enjoyed', 'location', 'host', 'neighborhood', 'good', 'really', 'nice']\n",
      "\n",
      "Printing the most relevant words for Topic# 5\n",
      "['recommended', 'just', 'located', 'convenient', 'time', 'close', 'exactly', 'pike', 'cozy', 'looking', 'seattle', 'amazing', 'staying', 'super', 'awesome', 'perfect', 'highly', 'clean', 'recommend', 'place']\n",
      "\n",
      "Printing the most relevant words for Topic# 6\n",
      "['living', 'night', 'accommodating', 'spacious', 'cozy', 'comfy', 'host', 'hosts', 'helpful', 'convenient', 'super', 'welcoming', 'private', 'bathroom', 'quiet', 'friendly', 'bed', 'clean', 'comfortable', 'room']\n",
      "\n",
      "Printing the most relevant words for Topic# 7\n",
      "['awesome', 'really', 'loved', 'lovely', 'guest', 'group', 'stayed', 'people', 'amazing', 'kitchen', 'located', 'perfect', 'staying', 'recommend', 'clean', 'neighborhood', 'time', 'family', 'beautiful', 'house']\n",
      "\n",
      "Printing the most relevant words for Topic# 8\n",
      "['helpful', 'lovely', 'future', 'cozy', 'love', 'loved', 'short', 'studio', 'cottage', 'perfect', 'visit', 'comfortable', 'thanks', 'wonderful', 'needed', 'really', 'seattle', 'enjoyed', 'definitely', 'stay']\n",
      "\n",
      "Printing the most relevant words for Topic# 9\n",
      "['away', 'check', 'hill', 'street', 'coffee', 'area', 'shops', 'space', 'parking', 'seattle', 'just', 'neighborhood', 'bus', 'close', 'distance', 'walk', 'walking', 'restaurants', 'downtown', 'easy']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, topic in enumerate(NMF_model.components_) : \n",
    "    print(f'Printing the most relevant words for Topic# {i}')\n",
    "    \n",
    "    # Get 20 words with the hightest coefficents \n",
    "    print([tfidf.get_feature_names()[idx] for idx in topic.argsort()[-20:]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
